{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejogiley/Novartis-Hackaton-7/blob/master/Notebooks/Lee_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHn__IVB5T2Q",
        "colab_type": "text"
      },
      "source": [
        "# Predicting affinities of antibiotic candidates to a DNA Gyrase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psUD7Ct3IxDH",
        "colab_type": "text"
      },
      "source": [
        "### Anaconda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDipX-nMAOFk",
        "colab_type": "code",
        "outputId": "d2cb6a07-b18c-49b2-d6c6-81bac8a4b317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#!wget -c https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "#!chmod +x Anaconda3-5.1.0-Linux-x86_64.sh\n",
        "#!bash ./Anaconda3-5.1.0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "#!conda install -q -y --prefix /usr/local -c omnia --no-update-deps pdbfixer=1.4\n",
        "#!conda install -q -y --prefix /usr/local -c conda-forge --no-update-deps xgboost=0.6a2\n",
        "#!conda install -q -y --prefix /usr/local -c rdkit --no-update-deps rdkit=2017.09.1\n",
        "#!conda install -q -y --prefix /usr/local -c deepchem --no-update-deps  deepchem-gpu=2.1.0\n",
        "\n",
        "#import sys\n",
        "#sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
        "\n",
        "!pip install keras_sequential_ascii"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_sequential_ascii in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras_sequential_ascii) (2.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras_sequential_ascii) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoBrxoKE3LfC",
        "colab_type": "text"
      },
      "source": [
        "### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ksekxnts6Lq",
        "colab_type": "code",
        "outputId": "24ebdce4-ebab-431b-803f-95f4e9d5e75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy  as np      # scientific computing: arrays\n",
        "import scipy  as sp      # scientific computing: statistics\n",
        "import pandas as pd      # data analysis tools\n",
        "\n",
        "# Tensor operations\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "# Neural Network\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, BatchNormalization\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.initializers import RandomUniform\n",
        "from keras_sequential_ascii import keras2ascii\n",
        "\n",
        "# Data processing & Cross-validation\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Stats\n",
        "from scipy.stats import linregress, kendalltau, spearmanr\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed\n",
        "seed = 84\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0j_1SHZYH7D",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZkapqVuI9gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_eval(model):\n",
        "    \n",
        "    plt.rcParams[\"figure.figsize\"] = (18,6)\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    c = 'blue'                                   # train -- blue\n",
        "    ax.scatter(y_train, model.predict(x_train),\n",
        "               s=65, c=c, zorder=10, edgecolors='k')\n",
        "    c = 'red'                                    # tests -- red\n",
        "    ax.scatter(y_test,  model.predict(x_test),\n",
        "               s=65, c=c, cmap=plt.cm.coolwarm, \n",
        "               zorder=10, edgecolors='k')\n",
        "    \n",
        "    ax.set_xlabel(\"pIC50 experimental\", fontsize=16)\n",
        "    ax.set_ylabel(\"pIC50 prediction\",   fontsize=16)\n",
        "    \n",
        "    #lims = [\n",
        "    #    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
        "    #    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
        "    #]\n",
        "    \n",
        "    lims = [-4, 4]\n",
        "    # now plot both limits against eachother\n",
        "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlim(lims)\n",
        "    ax.set_ylim(lims)\n",
        "    \n",
        "    # integer limits\n",
        "    ilims = [int(x+0.5) for x in lims]\n",
        "    ax.set_xticks(np.arange(*ilims,1))\n",
        "    ax.set_yticks(np.arange(*ilims,1))\n",
        "    \n",
        "    # We change the fontsize of minor ticks label \n",
        "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "    ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwGJl-kbYS6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_valid(models, titles):\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, sharey=False)\n",
        "    \n",
        "    i = 0\n",
        "    a = 0\n",
        "    b = 0\n",
        "    \n",
        "    for model in models:\n",
        "        \n",
        "        b  = int(i%2)\n",
        "        a  = int(i/2)\n",
        "        ax = axes[a, b]\n",
        "        \n",
        "        ax.title.set_text(titles[i])\n",
        "        i += 1\n",
        "        \n",
        "        c = vy.astype(int)\n",
        "        ax.scatter(vy,  model.predict(vx),\n",
        "                   s=65, c=c, cmap=plt.cm.coolwarm, \n",
        "                   zorder=10, edgecolors='k')\n",
        "        \n",
        "        ax.set_xlabel(\"pIC50 experimental\", fontsize=16)\n",
        "        ax.set_ylabel(\"pIC50 prediction\",   fontsize=16)\n",
        "        \n",
        "        #lims = [\n",
        "        #    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
        "        #    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
        "        #]\n",
        "                \n",
        "        lims = [-4, 4]\n",
        "        # now plot both limits against eachother\n",
        "        ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "        ax.set_aspect('equal')\n",
        "        ax.set_xlim(lims)\n",
        "        ax.set_ylim(lims)\n",
        "        \n",
        "        # integer limits\n",
        "        ilims = [int(x+0.5) for x in lims]\n",
        "        ax.set_xticks(np.arange(*ilims,1))\n",
        "        ax.set_yticks(np.arange(*ilims,1))\n",
        "        \n",
        "        # We change the fontsize of minor ticks label \n",
        "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "        \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4krUd-TDdtAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "    \n",
        "    # plot size\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "    \n",
        "    # Get training and test loss histories\n",
        "    training_loss = history.history['loss']\n",
        "    test_loss = history.history['val_mytest_loss']\n",
        "    \n",
        "    # Create count of the number of epochs\n",
        "    epoch_count = range(1, len(training_loss) + 1)\n",
        "    \n",
        "    # Visualize loss history\n",
        "    plt.plot(epoch_count, training_loss, 'b-')\n",
        "    plt.plot(epoch_count, test_loss, 'r-')\n",
        "    \n",
        "    plt.legend(['Training', 'Test'], fontsize=14)\n",
        "    \n",
        "    plt.xlabel('Epoch', fontsize=14)\n",
        "    plt.ylabel('Loss',  fontsize=14)\n",
        "    \n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHInvgqAeco3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_validation(method, steps):\n",
        "    \n",
        "    kf = KFold(n_splits=4, random_state=3, shuffle=True)\n",
        "    \n",
        "    for train_index, test_index in kf.split(f):\n",
        "        \n",
        "        # split trick\n",
        "        cv_ftrain, cv_ftests = f[train_index], f[test_index]\n",
        "        cv_ytrain, cv_ytests = y[train_index], y[test_index]\n",
        "        \n",
        "        cv_xtests = cv_ftests[:,:-5]\n",
        "        cv_xtrain = cv_ftrain[:,:-5]\n",
        "        \n",
        "        cv_s0train = cv_ftrain[:,-1]\n",
        "        cv_s2train = cv_ftrain[:,-2]\n",
        "        cv_s1train = cv_ftrain[:,-3]\n",
        "        \n",
        "        cv_rcutoff_train = cv_ftrain[:,-4]\n",
        "        cv_lcutoff_train = cv_ftrain[:,-5]\n",
        "        \n",
        "        input_dim = cv_xtrain.shape[1]\n",
        "        \n",
        "        model = None \n",
        "        model = method(input_dim)\n",
        "        model.fit(cv_xtrain, cv_ytrain, epochs=steps, verbose=0)\n",
        "        \n",
        "        slope, intercept, r_value, p_value, std_err = linregress(cv_ytests, model.predict(cv_xtests)[:,0])\n",
        "        tau, p_value                                = kendalltau(cv_ytests, model.predict(cv_xtests)[:,0])\n",
        "        mae                                         = mean_absolute_error(cv_ytests, model.predict(cv_xtests)[:,0])\n",
        "        \n",
        "        print(\"#------------------------#\")\n",
        "        print(\"R2          : %s\" % r_value)\n",
        "        print(\"MAE         : %s\" % mae)\n",
        "        print(\"Kendall Tau : %s\" % tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-91WLuFsLbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_results(model, name):\n",
        "    dt = {'y_train': y_train,'y_train_pred': network.predict(x_train)[:,0],\n",
        "          'y_tests':  y_test,'y_tests_pred': network.predict( x_test)[:,0]}\n",
        "    df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in dt.items() ]))\n",
        "    df.to_csv(name + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jShC7kQE6Ilp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Standarize(x):\n",
        "    # Z-score Estimator\n",
        "    x = (x - x.mean(axis=0)) / x.std(axis=0)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97eR-gYMNUG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Normalize(x):\n",
        "    # Tanh Estimator\n",
        "    x = Standarize(x)\n",
        "    return 0.5 * (np.tanh(0.01 * x) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfMNg6kwHLRO",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Data Processing</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRXDV7lBigWO",
        "colab_type": "text"
      },
      "source": [
        "### Read IC50 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7_WVRSM7XJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load features dataset\n",
        "filepath = \"https://raw.githubusercontent.com/alejogiley/Novartis-Hackaton-7/master/Data/Gyrase/AZ_Pyrrolamides_features_final.csv\"\n",
        "datasets = pd.read_csv(filepath)\n",
        "\n",
        "# rename\n",
        "datasets.rename(columns={'SAU Gyr IC50 (ç¤›)':'pIC50'}, inplace=True)\n",
        "\n",
        "pattern = \"[<]\"\n",
        "filters = datasets.pIC50.str.contains(pattern)\n",
        "datasets[\"left_saturated\"] = filters\n",
        "\n",
        "pattern = \"[>]\"\n",
        "filters = datasets.pIC50.str.contains(pattern)\n",
        "datasets[\"right_saturated\"] = filters\n",
        "\n",
        "# Reorder dataframe\n",
        "cols = datasets.columns.tolist()\n",
        "cols = cols[:2] + cols[-2:] + cols[2:-2]\n",
        "datasets = datasets[cols]\n",
        "\n",
        "datasets['pIC50'] = datasets['pIC50'].str.replace(r'[><]', '')\n",
        "datasets['pIC50'] = datasets['pIC50'].apply(lambda x: np.log10(float(x)))\n",
        "\n",
        "# drop Ipc\n",
        "datasets.drop(['Ipc'], axis=1, inplace=True)\n",
        "cols.remove('Ipc')\n",
        "\n",
        "# remove fraction-features\n",
        "# datasets.drop(cols[76:], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cej1rPmHVK1",
        "colab_type": "text"
      },
      "source": [
        "Check features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp4icQsDxAZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = datasets.corr()\n",
        "corr.loc[(corr['pIC50'] >= 0.4) | (corr['pIC50'] <= -0.4)]['pIC50'][1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOPPXCHl9j3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = datasets.columns.tolist()\n",
        "\n",
        "# Drop empty columns\n",
        "for col in cols:\n",
        "    if datasets[col].sum() == 0:\n",
        "        datasets.drop([col], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgNgnssm-QJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create correlation matrix\n",
        "# corr_matrix = datasets.corr().abs()\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "\n",
        "# Find features with correlation greater than 0.95\n",
        "# to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "\n",
        "# Drop features \n",
        "# for col in to_drop:\n",
        "#    datasets.drop(col, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xswfc23X-gaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How many descriptors were removed\n",
        "old = len(cols[4:])\n",
        "new = len(datasets.columns.tolist()[4:])\n",
        "print(\"%i descriptors were removed\" % (old - new))\n",
        "\n",
        "# Update descriptors list\n",
        "descriptors = datasets.columns.tolist()[4:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMKJ6GI_ilIC",
        "colab_type": "text"
      },
      "source": [
        "### Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_uM-OUUn9ld",
        "colab_type": "text"
      },
      "source": [
        "Split the machine-learning-ready dataset into __training__, __test__ and __validation__ subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3X88qpukiBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input and Output\n",
        "\n",
        "y = datasets['pIC50'].copy()\n",
        "y = y.astype('float64').to_numpy()\n",
        "\n",
        "x = datasets[descriptors].copy()\n",
        "x = x.astype('float64').to_numpy()\n",
        "\n",
        "# S: qualifiers classification\n",
        "\n",
        "s1 = datasets['left_saturated' ].apply(lambda x: x*1).copy()\n",
        "s2 = datasets['right_saturated'].apply(lambda x: x*1).copy()\n",
        "\n",
        "s1 = s1.to_numpy()\n",
        "s2 = s2.to_numpy()\n",
        "\n",
        "s0 = s1 + s2\n",
        "\n",
        "# CUTOFFS: > greater\n",
        "\n",
        "rcutoff = s2 * datasets['pIC50'].copy().astype('float64')\n",
        "rcutoff = rcutoff.to_numpy()\n",
        "\n",
        "# CUTOFFS: < lower\n",
        "\n",
        "lcutoff = s1 * datasets['pIC50'].copy().astype('float64')\n",
        "lcutoff = lcutoff.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JaJyn90mKbq-",
        "colab": {}
      },
      "source": [
        "# split dataset and update \\\n",
        "# qualifiers S and CUTOFFS\n",
        "\n",
        "f = np.vstack((x.T, lcutoff, rcutoff, s1, s2, s0)).T\n",
        "f_train, f_test, y_train, y_test = train_test_split(f, y, test_size=0.25, random_state=seed)\n",
        "\n",
        "x_train, x_test  = f_train[:,:-5], f_test[:,:-5]\n",
        "\n",
        "s0_train, s0_test = f_train[:,-1], f_test[:,-1]\n",
        "s2_train, s2_test = f_train[:,-2], f_test[:,-2]\n",
        "s1_train, s1_test = f_train[:,-3], f_test[:,-3]\n",
        "\n",
        "rcutoff_train, rcutoff_test = f_train[:,-4], f_test[:,-4]\n",
        "lcutoff_train, lcutoff_test = f_train[:,-5], f_test[:,-5]\n",
        "\n",
        "# Normalized features\n",
        "# tanh normalization\n",
        "\n",
        "#x_train = Normalize(x_train)\n",
        "#x_test  = Normalize(x_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-vlcFA0VHZ8",
        "colab_type": "text"
      },
      "source": [
        "## <font color='lightgreen'>Model Parameters</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgBAyJ1KVL-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "learning_rate = 1e-4\n",
        "number_of_epochs = 120\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cd4mpqOQIJBr",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Neural Network</font>\n",
        "\n",
        "A simple Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adH-v8aYok6h",
        "colab_type": "text"
      },
      "source": [
        "### <font color='blue'>LOSS FUNCTION - with censored data</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kDEaySUojyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss2(y_true, y_pred):\n",
        "    '''Loss function for censored dataset\n",
        "    '''\n",
        "    # Get deltas\n",
        "    z = y_pred - y_true\n",
        "    r = y_pred - rcutoff_train\n",
        "    l = y_pred - lcutoff_train\n",
        "    \n",
        "    # MSE for normal points\n",
        "    norm = (1 - s0_train) * K.square(z)\n",
        "    \n",
        "    # ReLU for censored points\n",
        "    righ = s2_train * K.relu(K.sign(-r)*K.square(-r))\n",
        "    left = s1_train * K.relu(K.sign( l)*K.square( l))\n",
        "    \n",
        "    return K.mean( norm + righ + left, axis=-1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZJYzsObqmAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    '''Loss function for censored dataset\n",
        "    '''\n",
        "    # Get deltas\n",
        "    z = y_pred - y_true\n",
        "    r = y_pred - rcutoff_train\n",
        "    l = y_pred - lcutoff_train\n",
        "    \n",
        "    # MSE for normal points\n",
        "    norm = (1 - s0_train) * K.square(z)\n",
        "    \n",
        "    # ReLU for censored points\n",
        "    righ = s2_train * K.relu(-r)\n",
        "    left = s1_train * K.relu( l)\n",
        "    \n",
        "    return K.mean( norm + righ + left, axis=-1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o1D-c5O09OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mytest_loss(y_true, y_pred):\n",
        "    '''Loss function for censored dataset\n",
        "    '''\n",
        "    # Get deltas\n",
        "    z = y_pred - y_true\n",
        "    r = y_pred - rcutoff_test\n",
        "    l = y_pred - lcutoff_test\n",
        "    \n",
        "    # MSE for normal points\n",
        "    norm = (1 - s0_test) * K.square(z)\n",
        "    \n",
        "    # ReLU for censored points\n",
        "    righ = s2_test * K.relu(-r)\n",
        "    left = s1_test * K.relu( l)\n",
        "    \n",
        "    return K.mean( norm + righ + left, axis=-1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG7zUqyZt6rc",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODU3luRZ2bvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The performance of common machine-learning algorithms can be very sensitive \n",
        "#to preprocessing of the data, neural networks mostly. Here we will normalize \n",
        "#the features and log(IC50) to have zero-mean and unit-standard-deviation \n",
        "#BatchNormalization\n",
        "\n",
        "# Function to create model\n",
        "\n",
        "def create_model(x):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # input layer\n",
        "    model.add(Dense(units=100, \n",
        "                    input_shape=(x, ), \n",
        "                    kernel_initializer='random_uniform',\n",
        "                    bias_initializer='ones'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=25))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation='linear'))\n",
        "    \n",
        "    model.compile(loss=custom_loss,                              # Custom loss function\n",
        "                  optimizer=Adam(lr=learning_rate, decay=1e-6),  # Adam optimizer\n",
        "                  metrics=['accuracy', mytest_loss]) \t         # measure performace\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKWmLyDbPcrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Clearing the NN\n",
        "network = None \n",
        "network = create_model(input_dim) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB060oRDrLbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visulaize\n",
        "keras2ascii(network)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6AqbU5hpdr1",
        "colab_type": "text"
      },
      "source": [
        "### Run Lola, Run\n",
        "\n",
        "Parameters are not optimized! No Grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ce2Fu0pu_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Train neural network\n",
        "history = network.fit(x_train,                          # Features\n",
        "                      y_train,                          # Target\n",
        "                      epochs=number_of_epochs,          # Number of epochs\n",
        "                      verbose=0,                        # No output\n",
        "                      batch_size=batch_size,            # Number of observations per batch\n",
        "                      validation_data=(x_test, y_test)) # Data for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94SB008avqlS",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWcN9gNrvph1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#network.save(\"/content/network.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM7ZUvTA4-tI",
        "colab_type": "text"
      },
      "source": [
        "### <font color='red'>Load model</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2MsmHNM5BlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#network = None\n",
        "#network = create_model(x.shape[1])\n",
        "#network.load_weights('/content/network.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z8o-yS-H3yo",
        "colab_type": "text"
      },
      "source": [
        "### Optimization performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j08gPVT-Uf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2F7_8x4xC6",
        "colab_type": "text"
      },
      "source": [
        "### Plot prediction vs experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSHfqw674XHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_eval(network)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZvlMgc730oI",
        "colab_type": "text"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ6zZOsv24_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_results(network, \"MSE+RELU_NN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vouaqEX27sOT",
        "colab_type": "text"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzg9XfkCSgVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slope, intercept, r_value, p_value, std_err = linregress(y_test, network.predict(x_test)[:,0])\n",
        "tau, p_value                                = kendalltau(y_test, network.predict(x_test)[:,0])\n",
        "mae                                         = mean_absolute_error(y_test, network.predict(x_test)[:,0])\n",
        "\n",
        "print(\"R2          : %s\" % r_value)\n",
        "print(\"MAE         : %s\" % mae)\n",
        "print(\"Kendall Tau : %s\" % tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5QIAbuopRgY",
        "colab_type": "text"
      },
      "source": [
        "### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9TRMHgfqN8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cross_validation(create_model, 60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWjXP5MteRo3",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Linear Model</font>\n",
        "\n",
        "A strightforward linear regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b70xlsTUHV1B",
        "colab_type": "text"
      },
      "source": [
        "### Single Layer Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jFAA27oe4rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create model\n",
        "def create_linear(x):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # input layer\n",
        "    model.add(Dense(units=1, \n",
        "                    input_shape=(x, ), \n",
        "                    kernel_initializer='random_uniform',\n",
        "                    bias_initializer='ones'))\n",
        "    model.add(Activation(\"linear\"))\n",
        "    \n",
        "    model.compile(loss=custom_loss,                              # Custom loss function\n",
        "                  optimizer=Adam(lr=learning_rate, decay=1e-6),  # Adam optimizer\n",
        "                  metrics=['mse']) \t                             # measure performace\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItaPfWlfRrJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x.shape[1]\n",
        "\n",
        "# Clearing the LM\n",
        "shallow = None \n",
        "shallow = create_linear(input_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ede6elC0LOaT",
        "colab_type": "text"
      },
      "source": [
        "### Rum, Rum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmTyl0zSeQTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train shallow model\n",
        "history = shallow.fit(x_train,                          # Features\n",
        "                      y_train,                          # Target\n",
        "                      epochs=number_of_epochs,          # Number of epochs\n",
        "                      verbose=0,                        # No output\n",
        "                      validation_data=(x_test, y_test)) # Data for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpeAYVeOHftC",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlbf-pgmHkhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shallow.save(\"/content/shallow.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gl6U9D38yQt",
        "colab_type": "text"
      },
      "source": [
        "### <font color='red'>Load model</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb-ox6d180ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shallow = None\n",
        "#shallow = create_linear(x.shape[1])\n",
        "#shallow.load_weights('/content/shallow.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCs-RbiCHtK3",
        "colab_type": "text"
      },
      "source": [
        "### Plot prediction vs experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJEshFNSfTv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_eval(shallow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuIGw9U94bw0",
        "colab_type": "text"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KPV03Bt4ghM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_results(shallow, \"MSE+RELU_LM\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBahxfa2H2QF",
        "colab_type": "text"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QvqSfZG0704",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slope, intercept, r_value, p_value, std_err = linregress(y_test, shallow.predict(x_test)[:,0])\n",
        "tau, p_value                                = kendalltau(y_test, shallow.predict(x_test)[:,0])\n",
        "mae                                         = mean_absolute_error(y_test, shallow.predict(x_test)[:,0])\n",
        "\n",
        "print(\"R2          : %s\" % r_value)\n",
        "print(\"MAE         : %s\" % mae)\n",
        "print(\"Kendall Tau : %s\" % tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXlvHs8vH9XL",
        "colab_type": "text"
      },
      "source": [
        "### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UxI_NLhfXlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cross_validation(create_linear, 60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdl6qg4aIKOh",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Control FCNN</font>\n",
        "\n",
        "Repeat the previous methods but ignore censored data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fml9dgp4J95t",
        "colab_type": "text"
      },
      "source": [
        "### <font color='blue'>LOSS FUNCTION - without censored data</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ljfz8CXXISol",
        "colab": {}
      },
      "source": [
        "def normal_loss(y_true, y_pred):\n",
        "    '''Loss function for censored dataset\n",
        "       training    \n",
        "    '''\n",
        "    z = y_pred - y_true\n",
        "    return K.mean((1-s0_train)*K.square(z), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WG4yzfd7zUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mytest_loss(y_true, y_pred):\n",
        "    '''Loss function for censored dataset\n",
        "       testing\n",
        "    '''\n",
        "    z = y_pred - y_true\n",
        "    return K.mean((1-s0_test)*K.square(z), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tatO6bpMKSjD",
        "colab_type": "text"
      },
      "source": [
        "### Fully Connected Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgD3JVXKrj0O",
        "colab": {}
      },
      "source": [
        "#The performance of common machine-learning algorithms can be very sensitive \n",
        "#to preprocessing of the data, neural networks mostly. Here we will normalize \n",
        "#the features and log(IC50) to have zero-mean and unit-standard-deviation \n",
        "#BatchNormalization\n",
        "\n",
        "# Function to create model\n",
        "\n",
        "def create_model2(x):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # input layer\n",
        "    model.add(Dense(units=100, \n",
        "                    input_shape=(x, ), \n",
        "                    kernel_initializer='random_uniform',\n",
        "                    bias_initializer='ones'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # hidden layer\n",
        "    model.add(Dense(units=25))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    \n",
        "    # output layer\n",
        "    model.add(Dense(units=1, activation='linear'))\n",
        "    \n",
        "    model.compile(loss=normal_loss,                              # Normal loss function\n",
        "                  optimizer=Adam(lr=learning_rate, decay=1e-6),  # Adam optimizer\n",
        "                  metrics=['accuracy', mytest_loss]) \t         # measure performace\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is1O4ef0RmWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input dimensions\n",
        "input_dim = x_train.shape[1]\n",
        "\n",
        "# fix random seed\n",
        "seed = 84\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Clearing the NN\n",
        "network2 = None \n",
        "network2 = create_model(input_dim) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LiCzovQf5KB",
        "colab_type": "text"
      },
      "source": [
        "### Corre Lolita"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oU5_ZtReIap9",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Train neural network\n",
        "history = network2.fit(x_train,                          # Features\n",
        "                       y_train,                          # Target\n",
        "                       epochs=number_of_epochs,          # Number of epochs\n",
        "                       verbose=0,                        # No output\n",
        "                       batch_size=batch_size,            # Number of observations per batch\n",
        "                       validation_data=(x_test, y_test)) # Data for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUKKto_9KyPI",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L4ESFkJwBgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#network2.save(\"/content/network2.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X_N6-PkLjGd",
        "colab_type": "text"
      },
      "source": [
        "### <font color='red'>Load model</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx-fcmlKLlT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#network2 = None\n",
        "#network2 = create_model(x.shape[1])\n",
        "#network2.load_weights('/content/network2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYB7VJ0LenT",
        "colab_type": "text"
      },
      "source": [
        "### Optimization performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVt1p8CzcNH8",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfnzAphL0oO",
        "colab_type": "text"
      },
      "source": [
        "### Predictions versus Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oatGB-xYJBYl",
        "colab": {}
      },
      "source": [
        "plot_eval(network2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKTPxy-n4oLR",
        "colab_type": "text"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLm9GJ1g4qWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_results(network2, \"MSE_NN\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dRXxukqM7N-",
        "colab_type": "text"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CgiYO1Q-JKvg",
        "colab": {}
      },
      "source": [
        "slope, intercept, r_value, p_value, std_err = linregress(y_test, network2.predict(x_test)[:,0])\n",
        "tau, p_value                                = kendalltau(y_test, network2.predict(x_test)[:,0])\n",
        "mae                                         = mean_absolute_error(y_test, network2.predict(x_test)[:,0])\n",
        "\n",
        "print(\"R2          : %s\" % r_value)\n",
        "print(\"MAE         : %s\" % mae)\n",
        "print(\"Kendall Tau : %s\" % tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnuPiryUM-p-",
        "colab_type": "text"
      },
      "source": [
        "### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48bqJtatJQhm",
        "colab": {}
      },
      "source": [
        "#cross_validation(create_model2, 60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97v0csHXNKtw",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Control LM</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9DoreL3fq4B",
        "colab_type": "text"
      },
      "source": [
        "### Single Layer Net\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2f9JD_egfGay",
        "colab": {}
      },
      "source": [
        "# Function to create model\n",
        "def create_linear2(x):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    # input layer\n",
        "    model.add(Dense(units=1, \n",
        "                    input_shape=(x, ), \n",
        "                    kernel_initializer='random_uniform',\n",
        "                    bias_initializer='ones'))\n",
        "    model.add(Activation(\"linear\"))\n",
        "    \n",
        "    model.compile(loss=normal_loss,                              # Custom loss function\n",
        "                  optimizer=Adam(lr=learning_rate, decay=1e-6),  # Adam optimizer\n",
        "                  metrics=['mse']) \t                             # measure performace\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM4IZh8VRg_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clearing the LM\n",
        "shallow2 = None \n",
        "shallow2 = create_linear(input_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO4ba5quNYM5",
        "colab_type": "text"
      },
      "source": [
        "### Jogging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rlAp1dpCfUpF",
        "colab": {}
      },
      "source": [
        "# Train shallow model\n",
        "history = shallow2.fit(x_train,                          # Features\n",
        "                       y_train,                          # Target\n",
        "                       epochs=number_of_epochs,          # Number of epochs\n",
        "                       verbose=0,                        # No output\n",
        "                       validation_data=(x_test, y_test)) # Data for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzPttWpnNby6",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyHhtJ98wQPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shallow2.save(\"/content/shallow2.h5\")\n",
        "#print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePix_qiNd68",
        "colab_type": "text"
      },
      "source": [
        "### <font color='red'>Load model</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAxaljoSNi7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#shallow2 = None\n",
        "#shallow2 = create_linear(x.shape[1])\n",
        "#shallow2.load_weights('/content/shallow2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1cNwYbYN8fo",
        "colab_type": "text"
      },
      "source": [
        "### Predictions versus Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "52rHSNlPfZIm",
        "colab": {}
      },
      "source": [
        "plot_eval(shallow2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtuwJg4C49mQ",
        "colab_type": "text"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjq9qNpb4_Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_results(shallow2, \"MSE_LM\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMjqw3FqOE36",
        "colab_type": "text"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BB4GU5ayfeE2",
        "colab": {}
      },
      "source": [
        "slope, intercept, r_value, p_value, std_err = linregress(y_test, shallow2.predict(x_test)[:,0])\n",
        "tau, p_value                                = kendalltau(y_test, shallow2.predict(x_test)[:,0])\n",
        "mae                                         = mean_absolute_error(y_test, shallow2.predict(x_test)[:,0])\n",
        "\n",
        "print(\"R2          : %s\" % r_value)\n",
        "print(\"MAE         : %s\" % mae)\n",
        "print(\"Kendall Tau : %s\" % tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gQG_57VOHqm",
        "colab_type": "text"
      },
      "source": [
        "### Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4eU5qhJXfjPe",
        "colab": {}
      },
      "source": [
        "#cross_validation(create_linear2, 60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIdDjQWRqkmv",
        "colab_type": "text"
      },
      "source": [
        "## <font color='green'>Validation</font>\n",
        "\n",
        "External dataset from BindingDB for DNA Gyrase ([link](https://www.bindingdb.org/jsp/dbsearch/PrimarySearch_ki.jsp?polymerid=2626,50005944,2630,50004611,50006452&target=dna%20gyrase%20subunit%20b&tag=pol&startPg=0&submit=Search&energyterm=kJ%2Fmole&column=IC50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r27BtBnKOqKZ",
        "colab_type": "text"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73Yf1QBvqm9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load features dataset\n",
        "\n",
        "filepath = \"https://raw.githubusercontent.com/alejogiley/Novartis-Hackaton-7/master/Data/Gyrase/BindingDB_Gyrase_B_features.tsv\"\n",
        "validset = pd.read_csv(filepath)\n",
        "\n",
        "# Rename columns\n",
        "\n",
        "validset.rename(columns={'IC50':'pIC50'}, inplace=True)\n",
        "validset.drop(['Ipc'], axis=1, inplace=True)\n",
        "\n",
        "# Modify dataset\n",
        "\n",
        "validset['pIC50'] = validset['pIC50'].apply(lambda x: np.log10(float(x)))\n",
        "\n",
        "# Get x/y\n",
        "\n",
        "vy = validset['pIC50'].copy()\n",
        "vy = vy.astype('float64').to_numpy()\n",
        "\n",
        "vx = validset[descriptors].copy()\n",
        "vx = vx.astype('float64').to_numpy()\n",
        "\n",
        "# Normalized features\n",
        "# vx = Normalize(vx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_awwBflOXOJ",
        "colab_type": "text"
      },
      "source": [
        "### Plot pIC50 predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcWP6Verh-0Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShV5RT1GaUX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [network, network2, shallow, shallow2]\n",
        "titles = ['MSE+ReLU_NN','MSE_NN','MSE+ReLU_LM','MSE_LM']\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,14)\n",
        "plot_valid(models, titles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si1AZkbZ7JdX",
        "colab_type": "text"
      },
      "source": [
        "### Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxvmSBS87HtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 0\n",
        "for model in models:\n",
        "    dt = {'y': vy,'y_pred': model.predict(vx)[:,0] }\n",
        "    df = pd.DataFrame.from_dict(dt)\n",
        "    df.to_csv(\"validation_\" + titles[i] + \".csv\"); i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_MvPxFwtjOS",
        "colab_type": "text"
      },
      "source": [
        "### Statistical Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLTTRVMWtN8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['MSE+ReLu NN', 'MSE NN', 'MSE+ReLu LM', 'MSE LM']\n",
        "\n",
        "i = 0\n",
        "for name in [network, network2, shallow, shallow2]:\n",
        "    \n",
        "    slope, intercept, r_value, p_value, std_err = linregress(vy, name.predict(vx)[:,0])\n",
        "    tau, p_value                                = kendalltau(vy, name.predict(vx)[:,0])\n",
        "    rho, p_value                                = spearmanr( vy, name.predict(vx)[:,0])\n",
        "    mae                                         = mean_absolute_error(vy, name.predict(vx)[:,0])\n",
        "    mse                                         = mean_squared_error( vy, name.predict(vx)[:,0])\n",
        "    \n",
        "    print(\"##### METHOD: %s\" % labels[i])\n",
        "    print(\"Kendall Tau : %s\" % tau)\n",
        "    print(\"R2          : %s\" % r_value)\n",
        "    print(\"Spearman    : %s\" % rho)\n",
        "    print(\"MAE         : %s\" % mae)\n",
        "    print(\"RMSE        : %s\" % np.sqrt(mse))\n",
        "    print(\"\")\n",
        "    \n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIBWmUbkuFuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_eval(network2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}